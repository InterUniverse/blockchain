{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb412ff-7bc0-4339-a7f8-b7c3b7b741c5",
   "metadata": {},
   "source": [
    "# Extract and save Ethereum raw transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73b44e4-9a62-4c25-871b-5d15ce36d8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import datetime as dt\n",
    "\n",
    "from web3 import Web3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc27a832-a992-445f-aa5c-fe7bed3ab352",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1ac17-0fa0-41e7-be0b-de73c3691709",
   "metadata": {},
   "source": [
    "### Alchemy as the remote node provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe0eeda-b34a-446b-8973-ca2084575641",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALCHEMY_KEY = os.environ.get('KEY')\n",
    "w3 = Web3(Web3.HTTPProvider('https://eth-mainnet.alchemyapi.io/v2/'+ALCHEMY_KEY))\n",
    "\n",
    "url = 'https://eth-mainnet.alchemyapi.io/v2/'+ALCHEMY_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b337c9bf-2d5e-41dc-b370-ab5ea7d3a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_block_int = w3.eth.blockNumber\n",
    "# up_to_block_int = latest_block_int - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94e0249-e9aa-4593-9508-83b7667bd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_hist_txns(no_of_blocks, up_to_block_int):\n",
    "    block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(up_to_block_int - 1),True]}\n",
    "    block_json = requests.post(url, json=block_num_request_data).json()\n",
    "    block_details_list = block_json['result']['transactions']\n",
    "\n",
    "    # Create lists with the values from the first block\n",
    "    block_numbers_list = [int(block_json['result']['number'],16)]\n",
    "    block_transactions_list = [len(block_json['result']['transactions'])]\n",
    "    block_datetime = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "    block_datetime_list = [block_datetime.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "\n",
    "        # While loop\n",
    "    block_int = up_to_block_int - 1\n",
    "    while block_int > up_to_block_int - no_of_blocks:\n",
    "        block_int -= 1\n",
    "        block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(block_int),True]}\n",
    "        block_json = requests.post(url, json=block_num_request_data).json()\n",
    "\n",
    "        # Get the block number from the first transaction in the block and add to a list\n",
    "        block_numbers_list.append(int(block_json['result']['number'],16))\n",
    "\n",
    "        # Get the number of transactions each block and add to a list\n",
    "        block_transactions_list.append(len(block_json['result']['transactions']))\n",
    "\n",
    "        # Get the timestamp of each block and add to a list\n",
    "        block_timestamp = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "        block_datetime = block_timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        block_datetime_list.append(block_datetime)\n",
    "\n",
    "        # Get transaction details of each block and add to a list\n",
    "        block_details_list.extend(block_json['result']['transactions'])\n",
    "\n",
    "\n",
    "    # Create a dictionary with block info\n",
    "    block_info = {}\n",
    "    block_info['block_number'] = block_numbers_list\n",
    "    block_info['block_transactions'] = block_transactions_list\n",
    "    block_info['block_timestamp'] = block_datetime_list\n",
    "    \n",
    "    return block_info, block_details_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5d8c06-cdd1-4199-845f-b6dec33a28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_backward_hist_txns(no_of_blocks):\n",
    "    \n",
    "    # Identify the oldest block that was last extracted from block_info_log.json\n",
    "    up_to_block_int = block_info['block_number'][-1]\n",
    "    \n",
    "    \n",
    "    block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(up_to_block_int - 1),True]}\n",
    "    block_json = requests.post(url, json=block_num_request_data).json()\n",
    "    block_details_list = block_json['result']['transactions']\n",
    "\n",
    "    \n",
    "    # Create lists with the values from the first block\n",
    "    block_numbers_list = [int(block_json['result']['number'],16)]\n",
    "    block_transactions_list = [len(block_json['result']['transactions'])]\n",
    "    block_datetime = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "    block_datetime_list = [block_datetime.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "\n",
    "    \n",
    "    # While loop to get n number of blocks but excluding the last extracted block\n",
    "    block_int = up_to_block_int - 1\n",
    "    while block_int > up_to_block_int - no_of_blocks:\n",
    "        block_int -= 1\n",
    "        block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(block_int),True]}\n",
    "        block_json = requests.post(url, json=block_num_request_data).json()\n",
    "\n",
    "        # Get the block number from the first transaction in the block and add to a list\n",
    "        block_numbers_list.append(int(block_json['result']['number'],16))\n",
    "\n",
    "        # Get the number of transactions each block and add to a list\n",
    "        block_transactions_list.append(len(block_json['result']['transactions']))\n",
    "\n",
    "        # Get the timestamp of each block and add to a list\n",
    "        block_timestamp = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "        block_datetime = block_timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        block_datetime_list.append(block_datetime)\n",
    "\n",
    "        # Get transaction details of each block and add to a list\n",
    "        block_details_list.extend(block_json['result']['transactions'])\n",
    "        \n",
    "    \n",
    "    # Save the block transactions\n",
    "    start_block = block_numbers_list[0]\n",
    "    end_block = block_numbers_list[-1]\n",
    "\n",
    "    block_details_str = json.dumps(block_details_list)\n",
    "    with open(f'{PATH}{start_block}_{end_block}_eth_transactions.json', 'w') as f:\n",
    "        f.write(block_details_str)\n",
    "        \n",
    "\n",
    "    # Update block info \n",
    "    block_info['block_number'].extend(block_numbers_list)\n",
    "    block_info['block_transactions'].extend(block_transactions_list)\n",
    "    block_info['block_timestamp'].extend(block_datetime_list)\n",
    "    \n",
    "    \n",
    "    # Save the block info log as json file (Original block_info_log.json is now DEPRECATED due to sorting error)\n",
    "    # block_info_str = json.dumps(block_info)\n",
    "    # with open(f'{PATH}block_info_log.json', 'w') as f:\n",
    "    #     f.write(block_info_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f04523b-5fac-4a3f-9a49-552241691a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_forward_hist_txns(no_of_blocks):\n",
    "    \n",
    "    # Identify the newest block that was last extracted from block_info_log.json\n",
    "    from_block_int = block_info['block_number'][0]\n",
    "    \n",
    "    \n",
    "    block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(from_block_int + 1),True]}\n",
    "    block_json = requests.post(url, json=block_num_request_data).json()\n",
    "    block_details_list = block_json['result']['transactions']\n",
    "\n",
    "    \n",
    "    # Create lists with the values from the first block\n",
    "    block_numbers_list = [int(block_json['result']['number'],16)]\n",
    "    block_transactions_list = [len(block_json['result']['transactions'])]\n",
    "    block_datetime = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "    block_datetime_list = [block_datetime.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "\n",
    "    \n",
    "    # While loop to get n number of blocks forward but exclude the newest extracted block in block info\n",
    "    block_int = from_block_int + 1\n",
    "    while block_int < from_block_int + no_of_blocks:\n",
    "        block_int += 1\n",
    "        block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(block_int),True]}\n",
    "        block_json = requests.post(url, json=block_num_request_data).json()\n",
    "\n",
    "        # Get the block number from the first transaction in the block and add to a list\n",
    "        block_numbers_list.append(int(block_json['result']['number'],16))\n",
    "\n",
    "        # Get the number of transactions each block and add to a list\n",
    "        block_transactions_list.append(len(block_json['result']['transactions']))\n",
    "\n",
    "        # Get the timestamp of each block and add to a list\n",
    "        block_timestamp = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "        block_datetime = block_timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        block_datetime_list.append(block_datetime)\n",
    "\n",
    "        # Get transaction details of each block and add to a list\n",
    "        block_details_list.extend(block_json['result']['transactions'])\n",
    "        \n",
    "    \n",
    "    # Save the block transactions\n",
    "    start_block = block_numbers_list[-1]\n",
    "    end_block = block_numbers_list[0]\n",
    "\n",
    "    block_details_str = json.dumps(block_details_list)\n",
    "    with open(f'{PATH}{start_block}_{end_block}_eth_transactions.json', 'w') as f:\n",
    "        f.write(block_details_str)\n",
    "        \n",
    "    \n",
    "    # Create a new block info dictionary\n",
    "    new_block_info = {}\n",
    "    new_block_info['block_number'] = sorted(block_numbers_list, reverse=True)\n",
    "    new_block_info['block_transactions'] = sorted(block_transactions_list, reverse=True)\n",
    "    new_block_info['block_timestamp'] = sorted(block_datetime_list, reverse=True)\n",
    "    \n",
    "    # Add existing block info to the new block info so that newest block info is always at the beginning of the list.\n",
    "    new_block_info['block_number'].extend(block_info['block_number'])\n",
    "    new_block_info['block_transactions'].extend(block_info['block_transactions'])\n",
    "    new_block_info['block_timestamp'].extend(block_info['block_timestamp'])\n",
    "    \n",
    "    \n",
    "    # Save the block info log as json file (Original block_info_log.json is now DEPRECATED due to sorting error)\n",
    "    # block_info_str = json.dumps(new_block_info)\n",
    "    # with open(f'{PATH}block_info_log.json', 'w') as f:\n",
    "    #     f.write(block_info_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7ddad8-50ba-4042-a57c-1235c57d8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txn_counts(no_of_blocks):\n",
    "    \n",
    "    from_block_int = block_txn['block_number'][-1]\n",
    "    # from_block_int = 12738502\n",
    "    \n",
    "    # Request for transaction counts based on block number\n",
    "    block_txn_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockTransactionCountByNumber\",\"params\":[hex(from_block_int + 1)]}\n",
    "    block_json = requests.post(url, json=block_txn_request_data).json()\n",
    "    block_transactions_list = [int(block_json['result'], 16)]\n",
    "    \n",
    "    # Requests for block information to get the timestamp of the block\n",
    "    block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(from_block_int + 1),False]}\n",
    "    block_json = requests.post(url, json=block_num_request_data).json()\n",
    "    block_numbers_list = [int(block_json['result']['number'],16)]\n",
    "    block_datetime = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "    block_datetime_list = [block_datetime.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "    \n",
    "    \n",
    "     # While loop to get n number of blocks forward but exclude the newest extracted block in block info\n",
    "    block_int = from_block_int + 1\n",
    "    while block_int < from_block_int + no_of_blocks:\n",
    "        block_int += 1\n",
    "        block_txn_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockTransactionCountByNumber\",\"params\":[hex(block_int)]}\n",
    "        block_json = requests.post(url, json=block_txn_request_data).json()\n",
    "\n",
    "        # Get the number of transactions each block and add to a list\n",
    "        block_transactions_list.append(int(block_json['result'], 16))\n",
    "\n",
    "        # Get the timestamp of each block and add to a list\n",
    "        block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(block_int),False]}\n",
    "        block_json = requests.post(url, json=block_num_request_data).json()\n",
    "    \n",
    "        block_timestamp = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "        block_datetime = block_timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        block_datetime_list.append(block_datetime)\n",
    "\n",
    "        # Get the block number from the first transaction in the block and add to a list\n",
    "        block_numbers_list.append(int(block_json['result']['number'],16))\n",
    "    \n",
    "    \n",
    "    # Create new block txn counts\n",
    "    # block_txn= {}\n",
    "    # block_txn['block_number'] = block_numbers_list\n",
    "    # block_txn['block_transactions'] = block_transactions_list\n",
    "    # block_txn['block_timestamp'] = block_datetime_list\n",
    "    \n",
    "    # Update block info\n",
    "    block_txn['block_number'].extend(block_numbers_list)\n",
    "    block_txn['block_transactions'].extend(block_transactions_list)\n",
    "    block_txn['block_timestamp'].extend(block_datetime_list)\n",
    "    \n",
    "    \n",
    "    # Save the block info log as json file\n",
    "    block_txn_str = json.dumps(block_txn)\n",
    "    with open(f'{PATH}block_txn_counts.json', 'w') as f:\n",
    "        f.write(block_txn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8b9ec7-f5ad-4779-bec8-570cd17b1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_specified_blocks_txns(list_of_blocks):\n",
    "    \n",
    "    first_block = list_of_blocks['block_number'][0]\n",
    "    block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(first_block),True]}\n",
    "    block_json = requests.post(url, json=block_num_request_data).json()\n",
    "    block_details_list = block_json['result']['transactions']\n",
    "    \n",
    "    block_numbers_list = [int(block_json['result']['number'],16)]\n",
    "    block_transactions_list = [len(block_json['result']['transactions'])]\n",
    "    \n",
    "    block_datetime = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "    block_datetime_list = [block_datetime.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "\n",
    "    \n",
    "    for block in list_of_blocks['block_number'][1:]:\n",
    "        block_num_request_data = {\"jsonrpc\": \"2.0\",\"id\": 0,\"method\": \"eth_getBlockByNumber\",\"params\":[hex(block),True]}\n",
    "        block_json = requests.post(url, json=block_num_request_data).json()\n",
    "        next_block_details_list = block_json['result']['transactions']\n",
    "\n",
    "        # Get the block number from the first transaction in the block and add to a list\n",
    "        block_numbers_list.append(int(block_json['result']['number'],16))\n",
    "\n",
    "        # Get the number of transactions each block and add to a list\n",
    "        block_transactions_list.append(len(block_json['result']['transactions']))\n",
    "\n",
    "        # Get the timestamp of each block and add to a list\n",
    "        block_timestamp = dt.datetime.fromtimestamp(int(block_json['result']['timestamp'],16))\n",
    "        block_datetime = block_timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        block_datetime_list.append(block_datetime)\n",
    "\n",
    "        # Get transaction details of each block and add to a list\n",
    "        block_details_list.extend(next_block_details_list)\n",
    "        \n",
    "    \n",
    "\n",
    "    block_details_str = json.dumps(block_details_list)\n",
    "    with open(f'{PATH}20220704_20220705_missing_eth_transactions.json', 'w') as f:\n",
    "        f.write(block_details_str)\n",
    "\n",
    "\n",
    "    # Create a dictionary with block info\n",
    "    temp_block_info = {}\n",
    "    temp_block_info['block_number'] = block_numbers_list\n",
    "    temp_block_info['block_transactions'] = block_transactions_list\n",
    "    temp_block_info['block_timestamp'] = block_datetime_list\n",
    "    \n",
    "    \n",
    "    # Save the temporary block info log as json file\n",
    "    temp_block_info_str = json.dumps(temp_block_info)\n",
    "    with open(f'{PATH}temp_block_info_log.json', 'w') as f:\n",
    "        f.write(temp_block_info_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de84b1-1398-4576-9b63-0b5ceb3ca392",
   "metadata": {},
   "source": [
    "### Read the block_extracted_log [DEPRECATED due to sorting error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21992e38-e82f-4b7a-9e03-b619553fd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_info = json.load(open(f'{PATH}block_info_log.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec44306-d999-4ec7-be33-9dbce2d12754",
   "metadata": {},
   "source": [
    "### While loop to batch extract the BACKWARD historical raw transactions using the Alchemy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b388a-d499-450c-b24a-129fa2e7d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved, batch = 0\n"
     ]
    }
   ],
   "source": [
    "# n = 0\n",
    "# while n < 10:\n",
    "#     extract_backward_hist_txns(no_of_blocks=1000)\n",
    "#     print('Data extracted and saved, batch =', n)\n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77009d-a6d7-412b-ac42-9f57815c0bf6",
   "metadata": {},
   "source": [
    "### While loop to batch extract the FORWARD historical raw transactions using the Alchemy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce644fa7-6324-4d58-be88-14f0af7c11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved, batch = 0\n",
      "Data extracted and saved, batch = 1\n",
      "Data extracted and saved, batch = 2\n",
      "Data extracted and saved, batch = 3\n",
      "Data extracted and saved, batch = 4\n",
      "Data extracted and saved, batch = 5\n",
      "Data extracted and saved, batch = 6\n"
     ]
    }
   ],
   "source": [
    "# n = 0\n",
    "# while n < 10:\n",
    "#     block_info = json.load(open(f'{PATH}block_info_log.json'))\n",
    "#     extract_forward_hist_txns(no_of_blocks=1000)\n",
    "#     print('Data extracted and saved, batch =', n)\n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7f7d5-dcd8-4f21-bb04-483420a8230a",
   "metadata": {},
   "source": [
    "### While loop to batch extract the FORWARD historical transaction counts using the Alchemy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5553a60-511e-4648-a208-687500d67c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0\n",
    "# while n < 2:\n",
    "#     block_txn = json.load(open(f'{PATH}block_txn_counts.json'))\n",
    "#     extract_txn_counts(no_of_blocks=1000)\n",
    "#     print('Data extracted and saved, batch =', n)\n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b9099-2756-47db-bc7a-ed0df2e05f72",
   "metadata": {},
   "source": [
    "### Extract missing blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02b15537-0880-4eef-a892-a100d3fa4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_blocks_list = json.load(open(f'{PATH}tmp_missing_blocks.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e84162bf-4897-4504-8ee6-972720abc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_specified_blocks_txns(missing_blocks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff51e2-3beb-425a-922b-0d924d4593ad",
   "metadata": {},
   "source": [
    "### Read the raw extracts into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1b34bc-78fe-4d93-aef6-936250b777a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = os.listdir(PATH)\n",
    "file_path_list = [os.path.join(PATH, file) for file in file_dir if file.endswith('transactions.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa8dc5a-f26e-4dd7-a381-73d852186414",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_sorted = sorted(file_path_list, key=os.path.getmtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349006f-363e-4a52-8f6c-e49e3e3c1760",
   "metadata": {},
   "source": [
    "#### Blocks from 1 July 2022 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e6e3c01-298d-439b-8830-6f678369db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3dcb372-3ae2-4d75-89a4-3cb9bb90f419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the index in the file path list\n",
    "idx = file_path_list.index('../data/raw/15053949_15052950_eth_transactions.json')\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecdb904-8795-4513-8f61-f43e0f30c3af",
   "metadata": {},
   "source": [
    "#### Manually read multiple json files in batches to save them as separate parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e252fd-4f08-4895-98f4-0daf2a2434af",
   "metadata": {},
   "source": [
    "Need to make sure we sort the file list first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ff528d-cb21-4fc7-8808-53a926ebac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d379db0b-cbed-4d48-a92a-2cecf9742a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw_json_list = [json.load(open(file)) for file in file_path_list[9:20]]\n",
    "# raw_json_list = [json.load(open(file)) for file in file_path_list[20:31]]\n",
    "# raw_json_list = [json.load(open(file)) for file in file_path_list[31:38]]\n",
    "# raw_json_list = [json.load(open(file)) for file in file_path_list[38:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce906ec-a315-487c-b012-35b08ca8e3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = pd.concat([pd.DataFrame(file) for file in raw_json_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44758972-b572-4b95-aeb2-d2ef82db91e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3088239, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "573bb8e8-6e25-4473-bca2-ec61d24c6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55537a8-4f27-4b7f-bfbc-c04d361e0864",
   "metadata": {},
   "source": [
    "### Convert all hexadecimal columns to decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4178edb4-2cc1-4851-b1a1-81b453fc136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['blockNumber','chainId','gas','gasPrice','nonce','nonce','transactionIndex','type','v','value','maxFeePerGas','maxPriorityFeePerGas']\n",
    "\n",
    "for col in col_list:\n",
    "    df[col] = df[col].apply(lambda x: int(x, base=16) if type(x) is str else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c2c85-e247-4b5c-94b1-6b5e238fb3b7",
   "metadata": {},
   "source": [
    "### Convert `type` into category data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99bc9b2c-adfe-40b6-9238-e8d9dd2d01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = df['type'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db7b3b-ee98-40ab-b6ea-63e3bcc7d747",
   "metadata": {},
   "source": [
    "### Convert `value` into float64 data type\n",
    "This allows the dataframe to be saved as parquet otherwise we get the following error:  \n",
    "\"Python int too large to convert to C long\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef95c3e1-be1d-45ce-80e5-29e4e6c11980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = df['value'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43ebc9-8ef4-4125-93e7-d7de8489af8a",
   "metadata": {},
   "source": [
    "### Add block timestamp to dataframe (block timestamp from block_info_log.json is incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8e37821-f751-4f46-ae2c-0be1794fcf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_info = json.load(open(f'{PATH}block_info_log.json'))\n",
    "# df_block_info = pd.DataFrame(block_info)\n",
    "\n",
    "# # Convert data type to datetime64[s]\n",
    "# df_block_info['block_timestamp'] = df_block_info['block_timestamp'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "683fa531-8c62-48d8-b359-7e62328447e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.merge(df_block_info[['block_number','block_timestamp']], left_on='blockNumber', right_on='block_number')\n",
    "# df.drop(columns='block_number', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ec97a-d5b6-44c8-81f6-e6ab5afcf878",
   "metadata": {},
   "source": [
    "### Add block timestamp to dataframe from block_txn_counts.json instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "017e2d0f-3244-453d-9ccc-d4d17893d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_txn = json.load(open(f'{PATH}block_txn_counts.json'))\n",
    "df_block_txn = pd.DataFrame(block_txn)\n",
    "\n",
    "# Convert data type to datetime64[s]\n",
    "df_block_txn['block_timestamp'] = df_block_txn['block_timestamp'].astype('datetime64[s]')\n",
    "df_block_txn['block_date'] = df_block_txn['block_timestamp'].astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f77a9572-3370-47a2-af1d-31a44e1a73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_block_txn[['block_number','block_timestamp','block_date']], left_on='blockNumber', right_on='block_number', how='left')\n",
    "df.drop(columns='block_number', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06265d41-e102-4cf4-9ca9-91a1678245c7",
   "metadata": {},
   "source": [
    "### Drop the `r`, `s`, `v` and `accessList` columns to reduce the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5230df7-0fb0-463c-9abd-bc74cd95be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['r','s','v','accessList'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b7bbe-bd47-41d8-bd3e-e0c3775e9329",
   "metadata": {},
   "source": [
    "### Save the pandas dataframe as parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3968790a-84b1-4c9b-a76b-e351d3c6c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_block = df['blockNumber'].max()\n",
    "min_block = df['blockNumber'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0192a93-41ec-4193-977f-e2d0776a0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb0f17c0-78f4-41b6-917e-a31f883b8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f'{OUT_PATH}df_eth_txns_{max_block}_{min_block}.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blockchain:Python",
   "language": "python",
   "name": "conda-env-blockchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
